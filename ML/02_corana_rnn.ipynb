{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### // 전염병 예측 인공지능 만들기\n",
    "\n",
    "#### // ======================================================================= 1. 코로나 19 확진자 예측 인공 지능 개발 원리\n",
    "#### // 3일 동안의 확진자 추이를 보고 다음 날의 확진자 수 예측\n",
    "#### // 인공지능은 3일 동안의 확진자 수를 보고 다음 날의 확진자 수가 어떻게 되었는지 학습\n",
    "#### // 만약 100일 동안의 확진자 수가 있다면 가장 먼저 1, 2, 3일차의 확진자 수가 어떻게 변하는지 살펴보고 4일차의 확진자 수를 학습\n",
    "#### // 그리고 2, 3, 4일차의 확진자 수가 어떻게 변하는지 살펴보고 5일차의 확진자 수를 학습.\n",
    "#### // 이러한 방식으로 계속 학습하여 97, 98, 99일차의 확진자 수로 100일차의 확진자 수를 학습.\n",
    "#### // 이러한 방식이 딥러닝의 여러 알고리즘 중 연속된 데이터에서 그 패턴을 찾아내는 순환 신경망 방식임.\n",
    "\n",
    "from keras.models import Sequential  ## 모델 도구\n",
    "from keras.layers import SimpleRNN, Dense  ## 순환 신경망 기법 및 각 레이어에서 뉴런의 수 설정\n",
    "from sklearn.preprocessing import MinMaxScaler  ## 데이터 정규화 및 전처리\n",
    "from sklearn.metrics import mean_squared_error  ## 결과의 정확도 계산\n",
    "from sklearn.model_selection import train_test_split  ## 데이터를 훈련 데이터와 검증 데이터로 분류하는 명령어\n",
    "from pandas import read_csv  ## \n",
    "\n",
    "## 수학 계산 라이브러리\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Confirmed\n",
      "0           24\n",
      "1           24\n",
      "2           27\n",
      "3           27\n",
      "4           28\n",
      "..         ...\n",
      "107      11190\n",
      "108      11206\n",
      "109      11225\n",
      "110      11265\n",
      "111      11344\n",
      "\n",
      "[112 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#### // 전염병 예측 인공지능 만들기\n",
    "\n",
    "#### // ======================================================================= 2. 데이터 불러오기\n",
    "#### // 외부 데이터를 사용하기 위해 깃허브에 있는 데이터를 불러온다.\n",
    "\n",
    "#!git clone https://github.com/yhlee1627/deeplearning.git\n",
    "dataframe = read_csv(r'C:/Users/chiu6/OneDrive/PythonWorkplace/99_Data/corona_daily.csv', usecols = [3], engine = 'python', skipfooter = 3)\n",
    "print(dataframe)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 23\n"
     ]
    }
   ],
   "source": [
    "#### // 전염병 예측 인공지능 만들기\n",
    "\n",
    "#### // ======================================================================= 3. 데이터 정규화 및 분류하기\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))  ## 데이터 정규화 범위를 0 ~ 1 사이의 값으로 결정.\n",
    "\n",
    "Dataset = scaler.fit_transform(dataset) ## 데이터 정규화 및 정규화 된 데이터를 변수에 대입\n",
    "\n",
    "train_data, test_data = train_test_split(Dataset, test_size = 0.2, shuffle = False)  \n",
    "## 훈련 데이터와 검증 데이터로 분류.\n",
    "## Dataset: 분류할 데이터 - 이 데이터는 정규화된 데이터이다.\n",
    "## test_size: 검증 데이터 비율\n",
    "## shuffle = False: 추출 방법 결정\n",
    "## 분류된 데이터를 각각의 변수에 대입 \n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
